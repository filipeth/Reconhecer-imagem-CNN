{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Project: Pet Classifier using CNN\n",
    "\n",
    "Prepration\n",
    "- Extract the ipynb file and the data in the same folder\n",
    "\n",
    "Data Set\n",
    "- A production grade program as 10,000 training images\n",
    "- This is a small program with 20 images of cats and 20 images of dogs. \n",
    "- The evaluation set has 10 images of cats and 10 images of dogs\n",
    "\n",
    "Runs\n",
    "- The student is expected to run the 100-300 training step\n",
    "- A production grade code would have about 20k-50k training steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filipetheodoro/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation, Conv2D, Input\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "def reset_model(model, Wsave):\n",
    "    model.set_weights(Wsave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyper parameters\n",
    "- Run the program with three num_steps : 100,200,300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "img_size = 32\n",
    "num_channels = 3\n",
    "img_size_flat = img_size * img_size * num_channels\n",
    "img_shape = (img_size, img_size)\n",
    "trainpath='./data/train'\n",
    "testpath='./data/test'\n",
    "labels = {'cats': [0,1], 'dogs': [1,0]}\n",
    "fc_size=32 #size of the output of final FC layer\n",
    "num_steps=[100, 200, 300] #Try 100, 200, 300. number of steps that training data should be looped. Usually 20K\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train image set 40\n",
      "X_data shape: (40, 32, 32, 3)\n",
      "y_data shape: (40, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def read_images_classes(basepath,imgSize=img_size):\n",
    "    image_stack = []\n",
    "    label_stack = []\n",
    "\n",
    "    for counter, l in enumerate(labels):\n",
    "        path = os.path.join(basepath, l,'*g')\n",
    "        for img in glob.glob(path):\n",
    "            one_hot_vector =np.zeros(len(labels),dtype=np.int16)\n",
    "            one_hot_vector[counter]=1\n",
    "            image = cv2.imread(img)\n",
    "            im_resize = cv2.resize(image,img_shape, interpolation=cv2.INTER_CUBIC)\n",
    "            image_stack.append(im_resize)\n",
    "            label_stack.append(labels[l])            \n",
    "    return np.array(image_stack), np.array(label_stack)\n",
    "\n",
    "X_train, y_train=read_images_classes(trainpath)\n",
    "X_test, y_test=read_images_classes(testpath)\n",
    "\n",
    "#test a sample image\n",
    "print('length of train image set',len(X_train))\n",
    "print('X_data shape:', X_train.shape)\n",
    "print('y_data shape:', y_train.shape)\n",
    "\n",
    "fig1 = plt.figure() \n",
    "ax1 = fig1.add_subplot(2,2,1) \n",
    "img = cv2.resize(X_train[0],(128,128), interpolation=cv2.INTER_CUBIC)\n",
    "ax1.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(y_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize our data values to the range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "X_train /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Build the model using keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model uses the following layers\n",
    "- input layer size[32,32,3]\n",
    "- conv layer 1 with 32 filters of kernel  size[5,5],\n",
    "- pooling layer 1 with pool size[2,2] and stride 2\n",
    "- conv layer 2 with 64 filters of kernel  size[5,5],\n",
    "- pooling layer 2 with pool size[2,2] and stride 2\n",
    "- dense layer whose output size is fixed in the hyper parameter: fc_size=32\n",
    "- drop out layer with droput probability 0.4\n",
    "- predict the class by doing a softmax on the output of the dropout layers\n",
    "\n",
    "Training\n",
    "- For training define the loss function and minimize it\n",
    "- For evaluation calculate the accuracy\n",
    "\n",
    "Reading Material\n",
    "- For ideas look at tensorflow layers tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# X_input = model.add(Input(shape=(img_size, img_size, num_channels)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), \n",
    "                        input_shape=(img_size, img_size, num_channels), \n",
    "#                         kernel_initializer='glorot_uniform',\n",
    "#                         bias_initializer='glorot_uniform',\n",
    "                        activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(fc_size, activation='elu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "Wsave = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                51232     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 104,994\n",
      "Trainable params: 104,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40 samples, validate on 20 samples\n",
      "Epoch 1/100\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 0.9357 - acc: 0.5250 - val_loss: 0.7335 - val_acc: 0.2500\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.8599 - acc: 0.4000 - val_loss: 0.9960 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.7708 - acc: 0.5250 - val_loss: 0.8456 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6629 - acc: 0.6500 - val_loss: 0.7497 - val_acc: 0.5500\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6379 - acc: 0.5500 - val_loss: 0.7465 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4464 - acc: 0.7500 - val_loss: 1.3022 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.7923 - acc: 0.6500 - val_loss: 1.0310 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3214 - acc: 0.8750 - val_loss: 1.1055 - val_acc: 0.5500\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5279 - acc: 0.7000 - val_loss: 1.0756 - val_acc: 0.4500\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3549 - acc: 0.8250 - val_loss: 1.1141 - val_acc: 0.4500\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2488 - acc: 0.9000 - val_loss: 1.2232 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1552 - acc: 0.9750 - val_loss: 1.4846 - val_acc: 0.5500\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1298 - acc: 0.9500 - val_loss: 1.5961 - val_acc: 0.4000\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1079 - acc: 0.9750 - val_loss: 1.4932 - val_acc: 0.4000\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1337 - acc: 0.9000 - val_loss: 1.5128 - val_acc: 0.4000\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0463 - acc: 1.0000 - val_loss: 1.8907 - val_acc: 0.5500\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0756 - acc: 0.9750 - val_loss: 1.5213 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0316 - acc: 1.0000 - val_loss: 1.4939 - val_acc: 0.5500\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0763 - acc: 0.9500 - val_loss: 1.4012 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0389 - acc: 1.0000 - val_loss: 1.3983 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0172 - acc: 1.0000 - val_loss: 1.3851 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0233 - acc: 1.0000 - val_loss: 1.4408 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 1.5512 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 1.6279 - val_acc: 0.5500\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 1.7024 - val_acc: 0.5500\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 1.7734 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 1.8951 - val_acc: 0.4000\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 1.9973 - val_acc: 0.4000\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.0478 - val_acc: 0.4500\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 2.0773 - val_acc: 0.5000\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 2.0848 - val_acc: 0.5000\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.0804 - val_acc: 0.5000\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 2.0718 - val_acc: 0.5000\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.4855e-04 - acc: 1.0000 - val_loss: 2.0660 - val_acc: 0.5000\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 2.0572 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.0565 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.0636 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 2.0690 - val_acc: 0.5000\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.0726 - val_acc: 0.5000\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.0813 - val_acc: 0.5000\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.0892 - val_acc: 0.5000\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.0962 - val_acc: 0.5000\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.1023 - val_acc: 0.5000\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 2.1100 - val_acc: 0.5000\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.0260e-04 - acc: 1.0000 - val_loss: 2.1200 - val_acc: 0.5000\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.1279 - val_acc: 0.5000\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.5636e-04 - acc: 1.0000 - val_loss: 2.1360 - val_acc: 0.5000\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.8320e-04 - acc: 1.0000 - val_loss: 2.1451 - val_acc: 0.5000\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 2.1576 - val_acc: 0.5000\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.1769 - val_acc: 0.5000\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.1915 - val_acc: 0.5000\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.2026 - val_acc: 0.5000\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.8451e-04 - acc: 1.0000 - val_loss: 2.2098 - val_acc: 0.5000\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.2281e-04 - acc: 1.0000 - val_loss: 2.2152 - val_acc: 0.5000\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.2158 - val_acc: 0.5000\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.5519e-04 - acc: 1.0000 - val_loss: 2.2092 - val_acc: 0.5000\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.2035 - val_acc: 0.5000\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.1432e-04 - acc: 1.0000 - val_loss: 2.1984 - val_acc: 0.5000\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.2869e-04 - acc: 1.0000 - val_loss: 2.1960 - val_acc: 0.5000\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.7929e-04 - acc: 1.0000 - val_loss: 2.2005 - val_acc: 0.5000\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.2039 - val_acc: 0.5000\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 5.2541e-04 - acc: 1.0000 - val_loss: 2.2024 - val_acc: 0.5000\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.5605e-04 - acc: 1.0000 - val_loss: 2.2024 - val_acc: 0.5000\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.2068 - val_acc: 0.5000\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.6986e-04 - acc: 1.0000 - val_loss: 2.2141 - val_acc: 0.5000\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.5676e-04 - acc: 1.0000 - val_loss: 2.2214 - val_acc: 0.5000\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.8445e-04 - acc: 1.0000 - val_loss: 2.2293 - val_acc: 0.5000\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.2363 - val_acc: 0.5000\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.6090e-04 - acc: 1.0000 - val_loss: 2.2433 - val_acc: 0.5000\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.3883e-04 - acc: 1.0000 - val_loss: 2.2518 - val_acc: 0.5000\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.5989e-04 - acc: 1.0000 - val_loss: 2.2588 - val_acc: 0.5000\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.2667 - val_acc: 0.5000\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.5087e-04 - acc: 1.0000 - val_loss: 2.2755 - val_acc: 0.5000\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.2796 - val_acc: 0.5000\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.4735e-04 - acc: 1.0000 - val_loss: 2.2793 - val_acc: 0.5000\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.8462e-04 - acc: 1.0000 - val_loss: 2.2785 - val_acc: 0.5000\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.5749e-04 - acc: 1.0000 - val_loss: 2.2804 - val_acc: 0.5000\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.4765e-04 - acc: 1.0000 - val_loss: 2.2841 - val_acc: 0.5000\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.2894 - val_acc: 0.5000\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.6207e-04 - acc: 1.0000 - val_loss: 2.2937 - val_acc: 0.5000\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.7379e-04 - acc: 1.0000 - val_loss: 2.2985 - val_acc: 0.5000\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.3080 - val_acc: 0.5000\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.5090e-04 - acc: 1.0000 - val_loss: 2.3165 - val_acc: 0.5000\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.9405e-04 - acc: 1.0000 - val_loss: 2.3228 - val_acc: 0.5000\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.3099e-04 - acc: 1.0000 - val_loss: 2.3286 - val_acc: 0.5000\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.1114e-04 - acc: 1.0000 - val_loss: 2.3332 - val_acc: 0.5000\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.3859e-04 - acc: 1.0000 - val_loss: 2.3374 - val_acc: 0.5000\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.5230e-04 - acc: 1.0000 - val_loss: 2.3421 - val_acc: 0.5000\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.3432 - val_acc: 0.5000\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.3534 - val_acc: 0.5000\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.6376e-04 - acc: 1.0000 - val_loss: 2.3721 - val_acc: 0.5000\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.9106e-04 - acc: 1.0000 - val_loss: 2.3887 - val_acc: 0.5000\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.8984e-04 - acc: 1.0000 - val_loss: 2.3991 - val_acc: 0.5000\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.4086 - val_acc: 0.5000\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.4097e-04 - acc: 1.0000 - val_loss: 2.4157 - val_acc: 0.5000\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.3308e-04 - acc: 1.0000 - val_loss: 2.4220 - val_acc: 0.5000\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.5275e-04 - acc: 1.0000 - val_loss: 2.4295 - val_acc: 0.5000\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.7492e-04 - acc: 1.0000 - val_loss: 2.4392 - val_acc: 0.5000\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.4534 - val_acc: 0.5000\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.0820e-04 - acc: 1.0000 - val_loss: 2.4675 - val_acc: 0.5000\n",
      "Test loss: 2.4675023555755615\n",
      "Test accuracy: 0.5\n",
      "Train on 40 samples, validate on 20 samples\n",
      "Epoch 1/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.7448 - acc: 0.5000 - val_loss: 0.9283 - val_acc: 0.5000\n",
      "Epoch 2/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.9036 - acc: 0.4750 - val_loss: 0.8282 - val_acc: 0.5000\n",
      "Epoch 3/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.9851 - acc: 0.4250 - val_loss: 0.7023 - val_acc: 0.5000\n",
      "Epoch 4/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6264 - acc: 0.6750 - val_loss: 0.7004 - val_acc: 0.6000\n",
      "Epoch 5/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6121 - acc: 0.7000 - val_loss: 0.7829 - val_acc: 0.4500\n",
      "Epoch 6/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5523 - acc: 0.7500 - val_loss: 0.7463 - val_acc: 0.6000\n",
      "Epoch 7/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4420 - acc: 0.7750 - val_loss: 0.7447 - val_acc: 0.4500\n",
      "Epoch 8/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3242 - acc: 0.8750 - val_loss: 0.8517 - val_acc: 0.4500\n",
      "Epoch 9/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2905 - acc: 0.9250 - val_loss: 0.9093 - val_acc: 0.4500\n",
      "Epoch 10/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2379 - acc: 0.9500 - val_loss: 0.9498 - val_acc: 0.4000\n",
      "Epoch 11/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2154 - acc: 0.9750 - val_loss: 1.0654 - val_acc: 0.5000\n",
      "Epoch 12/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1196 - acc: 1.0000 - val_loss: 1.1686 - val_acc: 0.4500\n",
      "Epoch 13/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0879 - acc: 1.0000 - val_loss: 1.2094 - val_acc: 0.4500\n",
      "Epoch 14/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1012 - acc: 0.9750 - val_loss: 1.2346 - val_acc: 0.5500\n",
      "Epoch 15/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0546 - acc: 1.0000 - val_loss: 1.2096 - val_acc: 0.5500\n",
      "Epoch 16/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0572 - acc: 1.0000 - val_loss: 1.1478 - val_acc: 0.5500\n",
      "Epoch 17/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0318 - acc: 1.0000 - val_loss: 1.1563 - val_acc: 0.5500\n",
      "Epoch 18/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0254 - acc: 1.0000 - val_loss: 1.2086 - val_acc: 0.5500\n",
      "Epoch 19/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0258 - acc: 1.0000 - val_loss: 1.2917 - val_acc: 0.5500\n",
      "Epoch 20/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0171 - acc: 1.0000 - val_loss: 1.3795 - val_acc: 0.5500\n",
      "Epoch 21/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0129 - acc: 1.0000 - val_loss: 1.4722 - val_acc: 0.5500\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 1.5495 - val_acc: 0.5000\n",
      "Epoch 23/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 1.6039 - val_acc: 0.5000\n",
      "Epoch 24/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.6529 - val_acc: 0.5000\n",
      "Epoch 25/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 1.6829 - val_acc: 0.5000\n",
      "Epoch 26/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 1.7050 - val_acc: 0.5000\n",
      "Epoch 27/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.7180 - val_acc: 0.5000\n",
      "Epoch 28/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 1.7274 - val_acc: 0.5000\n",
      "Epoch 29/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.7311 - val_acc: 0.5000\n",
      "Epoch 30/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 1.7333 - val_acc: 0.5000\n",
      "Epoch 31/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 1.7397 - val_acc: 0.5000\n",
      "Epoch 32/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.7515 - val_acc: 0.5000\n",
      "Epoch 33/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 1.7577 - val_acc: 0.5000\n",
      "Epoch 34/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 1.7608 - val_acc: 0.5000\n",
      "Epoch 35/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.7545 - val_acc: 0.5000\n",
      "Epoch 36/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 1.7496 - val_acc: 0.5500\n",
      "Epoch 37/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.7458 - val_acc: 0.5500\n",
      "Epoch 38/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.7477 - val_acc: 0.5500\n",
      "Epoch 39/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 1.7622 - val_acc: 0.5500\n",
      "Epoch 40/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.7802 - val_acc: 0.5500\n",
      "Epoch 41/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.7951 - val_acc: 0.5500\n",
      "Epoch 42/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.8094 - val_acc: 0.5500\n",
      "Epoch 43/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.8293 - val_acc: 0.5500\n",
      "Epoch 44/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.8563 - val_acc: 0.5500\n",
      "Epoch 45/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.8776 - val_acc: 0.5000\n",
      "Epoch 46/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.8936 - val_acc: 0.5000\n",
      "Epoch 47/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.9048 - val_acc: 0.5000\n",
      "Epoch 48/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 1.9184 - val_acc: 0.5000\n",
      "Epoch 49/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 1.9224 - val_acc: 0.5000\n",
      "Epoch 50/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 1.9268 - val_acc: 0.5000\n",
      "Epoch 51/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.9321 - val_acc: 0.5000\n",
      "Epoch 52/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.9396 - val_acc: 0.5000\n",
      "Epoch 53/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.9494 - val_acc: 0.5000\n",
      "Epoch 54/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.9625 - val_acc: 0.5000\n",
      "Epoch 55/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.9726 - val_acc: 0.5000\n",
      "Epoch 56/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 1.9745 - val_acc: 0.5000\n",
      "Epoch 57/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 1.9668 - val_acc: 0.5000\n",
      "Epoch 58/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.9640 - val_acc: 0.5000\n",
      "Epoch 59/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.9632 - val_acc: 0.5000\n",
      "Epoch 60/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.9649 - val_acc: 0.5000\n",
      "Epoch 61/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.9729 - val_acc: 0.5000\n",
      "Epoch 62/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.9828 - val_acc: 0.5000\n",
      "Epoch 63/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.9919 - val_acc: 0.5000\n",
      "Epoch 64/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.0031 - val_acc: 0.5000\n",
      "Epoch 65/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.0154 - val_acc: 0.5000\n",
      "Epoch 66/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.0243 - val_acc: 0.5000\n",
      "Epoch 67/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.0338 - val_acc: 0.5000\n",
      "Epoch 68/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.0442 - val_acc: 0.5000\n",
      "Epoch 69/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.0506 - val_acc: 0.5500\n",
      "Epoch 70/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.0576 - val_acc: 0.5500\n",
      "Epoch 71/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.0643 - val_acc: 0.5500\n",
      "Epoch 72/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 2.0645 - val_acc: 0.5500\n",
      "Epoch 73/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.8405e-04 - acc: 1.0000 - val_loss: 2.0621 - val_acc: 0.5500\n",
      "Epoch 74/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.0599 - val_acc: 0.5500\n",
      "Epoch 75/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.0596 - val_acc: 0.5500\n",
      "Epoch 76/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.0609 - val_acc: 0.5500\n",
      "Epoch 77/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.0612 - val_acc: 0.5500\n",
      "Epoch 78/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.0643 - val_acc: 0.5500\n",
      "Epoch 79/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.9671e-04 - acc: 1.0000 - val_loss: 2.0690 - val_acc: 0.5500\n",
      "Epoch 80/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.1620e-04 - acc: 1.0000 - val_loss: 2.0731 - val_acc: 0.5500\n",
      "Epoch 81/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.0785 - val_acc: 0.5500\n",
      "Epoch 82/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.2029e-04 - acc: 1.0000 - val_loss: 2.0848 - val_acc: 0.5500\n",
      "Epoch 83/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.0883 - val_acc: 0.5500\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.0930 - val_acc: 0.5500\n",
      "Epoch 85/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.1508e-04 - acc: 1.0000 - val_loss: 2.0941 - val_acc: 0.5500\n",
      "Epoch 86/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.0958 - val_acc: 0.5500\n",
      "Epoch 87/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.0969 - val_acc: 0.5500\n",
      "Epoch 88/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.0988 - val_acc: 0.5500\n",
      "Epoch 89/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.1021 - val_acc: 0.5500\n",
      "Epoch 90/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 2.1064 - val_acc: 0.5500\n",
      "Epoch 91/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.7935e-04 - acc: 1.0000 - val_loss: 2.1118 - val_acc: 0.5500\n",
      "Epoch 92/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.1185 - val_acc: 0.5500\n",
      "Epoch 93/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.1565e-04 - acc: 1.0000 - val_loss: 2.1237 - val_acc: 0.5500\n",
      "Epoch 94/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.0414e-04 - acc: 1.0000 - val_loss: 2.1284 - val_acc: 0.5500\n",
      "Epoch 95/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.4535e-04 - acc: 1.0000 - val_loss: 2.1330 - val_acc: 0.5500\n",
      "Epoch 96/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.1380 - val_acc: 0.5500\n",
      "Epoch 97/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.2468e-04 - acc: 1.0000 - val_loss: 2.1422 - val_acc: 0.5500\n",
      "Epoch 98/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.6251e-04 - acc: 1.0000 - val_loss: 2.1459 - val_acc: 0.5500\n",
      "Epoch 99/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.9919e-04 - acc: 1.0000 - val_loss: 2.1506 - val_acc: 0.5500\n",
      "Epoch 100/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.3977e-04 - acc: 1.0000 - val_loss: 2.1542 - val_acc: 0.5500\n",
      "Epoch 101/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.7764e-04 - acc: 1.0000 - val_loss: 2.1560 - val_acc: 0.5500\n",
      "Epoch 102/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 2.1525 - val_acc: 0.5500\n",
      "Epoch 103/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.7903e-04 - acc: 1.0000 - val_loss: 2.1426 - val_acc: 0.5500\n",
      "Epoch 104/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.1671e-04 - acc: 1.0000 - val_loss: 2.1360 - val_acc: 0.5500\n",
      "Epoch 105/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.1314 - val_acc: 0.5500\n",
      "Epoch 106/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.9109e-04 - acc: 1.0000 - val_loss: 2.1330 - val_acc: 0.5500\n",
      "Epoch 107/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.1376 - val_acc: 0.6000\n",
      "Epoch 108/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.1426 - val_acc: 0.6000\n",
      "Epoch 109/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.2080e-04 - acc: 1.0000 - val_loss: 2.1459 - val_acc: 0.5500\n",
      "Epoch 110/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.6707e-04 - acc: 1.0000 - val_loss: 2.1501 - val_acc: 0.5500\n",
      "Epoch 111/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.5518e-04 - acc: 1.0000 - val_loss: 2.1559 - val_acc: 0.5500\n",
      "Epoch 112/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.1648 - val_acc: 0.5500\n",
      "Epoch 113/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.3449e-04 - acc: 1.0000 - val_loss: 2.1711 - val_acc: 0.5500\n",
      "Epoch 114/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.8446e-04 - acc: 1.0000 - val_loss: 2.1758 - val_acc: 0.5500\n",
      "Epoch 115/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.4951e-04 - acc: 1.0000 - val_loss: 2.1792 - val_acc: 0.5500\n",
      "Epoch 116/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.7026e-04 - acc: 1.0000 - val_loss: 2.1821 - val_acc: 0.5500\n",
      "Epoch 117/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.2579e-04 - acc: 1.0000 - val_loss: 2.1850 - val_acc: 0.5500\n",
      "Epoch 118/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.1928 - val_acc: 0.5500\n",
      "Epoch 119/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.4971e-04 - acc: 1.0000 - val_loss: 2.1989 - val_acc: 0.5500\n",
      "Epoch 120/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.2749e-04 - acc: 1.0000 - val_loss: 2.2037 - val_acc: 0.5500\n",
      "Epoch 121/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.2097 - val_acc: 0.5500\n",
      "Epoch 122/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.0769e-04 - acc: 1.0000 - val_loss: 2.2143 - val_acc: 0.5500\n",
      "Epoch 123/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.8000e-04 - acc: 1.0000 - val_loss: 2.2199 - val_acc: 0.5500\n",
      "Epoch 124/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.8172e-04 - acc: 1.0000 - val_loss: 2.2255 - val_acc: 0.5500\n",
      "Epoch 125/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.8092e-04 - acc: 1.0000 - val_loss: 2.2293 - val_acc: 0.5500\n",
      "Epoch 126/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.6922e-04 - acc: 1.0000 - val_loss: 2.2324 - val_acc: 0.5500\n",
      "Epoch 127/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.5283e-04 - acc: 1.0000 - val_loss: 2.2346 - val_acc: 0.5500\n",
      "Epoch 128/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.5383e-04 - acc: 1.0000 - val_loss: 2.2369 - val_acc: 0.5500\n",
      "Epoch 129/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.6793e-04 - acc: 1.0000 - val_loss: 2.2417 - val_acc: 0.5500\n",
      "Epoch 130/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.1318e-04 - acc: 1.0000 - val_loss: 2.2471 - val_acc: 0.5500\n",
      "Epoch 131/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.1413e-04 - acc: 1.0000 - val_loss: 2.2529 - val_acc: 0.5500\n",
      "Epoch 132/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.3595e-04 - acc: 1.0000 - val_loss: 2.2581 - val_acc: 0.5500\n",
      "Epoch 133/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.2640 - val_acc: 0.5500\n",
      "Epoch 134/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.4758e-04 - acc: 1.0000 - val_loss: 2.2680 - val_acc: 0.5500\n",
      "Epoch 135/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.3977e-04 - acc: 1.0000 - val_loss: 2.2709 - val_acc: 0.5500\n",
      "Epoch 136/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.9537e-04 - acc: 1.0000 - val_loss: 2.2733 - val_acc: 0.5500\n",
      "Epoch 137/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.2466e-04 - acc: 1.0000 - val_loss: 2.2750 - val_acc: 0.5500\n",
      "Epoch 138/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.2786 - val_acc: 0.5500\n",
      "Epoch 139/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.5187e-04 - acc: 1.0000 - val_loss: 2.2804 - val_acc: 0.5500\n",
      "Epoch 140/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.8051e-04 - acc: 1.0000 - val_loss: 2.2817 - val_acc: 0.5500\n",
      "Epoch 141/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.6737e-04 - acc: 1.0000 - val_loss: 2.2835 - val_acc: 0.5500\n",
      "Epoch 142/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.8877e-04 - acc: 1.0000 - val_loss: 2.2830 - val_acc: 0.5500\n",
      "Epoch 143/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.2849 - val_acc: 0.5500\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 3.8661e-04 - acc: 1.0000 - val_loss: 2.2894 - val_acc: 0.6000\n",
      "Epoch 145/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.2753e-04 - acc: 1.0000 - val_loss: 2.2953 - val_acc: 0.6000\n",
      "Epoch 146/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.0702e-04 - acc: 1.0000 - val_loss: 2.3016 - val_acc: 0.6000\n",
      "Epoch 147/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.5047e-04 - acc: 1.0000 - val_loss: 2.3062 - val_acc: 0.6000\n",
      "Epoch 148/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.3124 - val_acc: 0.6000\n",
      "Epoch 149/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.3176e-04 - acc: 1.0000 - val_loss: 2.3168 - val_acc: 0.6000\n",
      "Epoch 150/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.6429e-04 - acc: 1.0000 - val_loss: 2.3214 - val_acc: 0.6000\n",
      "Epoch 151/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.0724e-04 - acc: 1.0000 - val_loss: 2.3265 - val_acc: 0.5500\n",
      "Epoch 152/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.0627e-04 - acc: 1.0000 - val_loss: 2.3297 - val_acc: 0.5500\n",
      "Epoch 153/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.5045e-04 - acc: 1.0000 - val_loss: 2.3312 - val_acc: 0.5500\n",
      "Epoch 154/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.3692e-04 - acc: 1.0000 - val_loss: 2.3327 - val_acc: 0.5500\n",
      "Epoch 155/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.5226e-04 - acc: 1.0000 - val_loss: 2.3359 - val_acc: 0.5500\n",
      "Epoch 156/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.6507e-04 - acc: 1.0000 - val_loss: 2.3400 - val_acc: 0.5500\n",
      "Epoch 157/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.7826e-04 - acc: 1.0000 - val_loss: 2.3440 - val_acc: 0.5500\n",
      "Epoch 158/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.8154e-04 - acc: 1.0000 - val_loss: 2.3472 - val_acc: 0.5500\n",
      "Epoch 159/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.5383e-04 - acc: 1.0000 - val_loss: 2.3499 - val_acc: 0.5500\n",
      "Epoch 160/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.2722e-04 - acc: 1.0000 - val_loss: 2.3535 - val_acc: 0.5500\n",
      "Epoch 161/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.6260e-04 - acc: 1.0000 - val_loss: 2.3595 - val_acc: 0.5500\n",
      "Epoch 162/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.8328e-04 - acc: 1.0000 - val_loss: 2.3645 - val_acc: 0.5500\n",
      "Epoch 163/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.3732 - val_acc: 0.5500\n",
      "Epoch 164/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.3851 - val_acc: 0.5500\n",
      "Epoch 165/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.7988e-04 - acc: 1.0000 - val_loss: 2.3986 - val_acc: 0.5500\n",
      "Epoch 166/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.7293e-04 - acc: 1.0000 - val_loss: 2.4093 - val_acc: 0.5500\n",
      "Epoch 167/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.0581e-04 - acc: 1.0000 - val_loss: 2.4167 - val_acc: 0.5500\n",
      "Epoch 168/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.7820e-04 - acc: 1.0000 - val_loss: 2.4224 - val_acc: 0.5500\n",
      "Epoch 169/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.9512e-04 - acc: 1.0000 - val_loss: 2.4271 - val_acc: 0.5500\n",
      "Epoch 170/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.5801e-04 - acc: 1.0000 - val_loss: 2.4308 - val_acc: 0.5500\n",
      "Epoch 171/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.0339e-04 - acc: 1.0000 - val_loss: 2.4346 - val_acc: 0.5500\n",
      "Epoch 172/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.9786e-04 - acc: 1.0000 - val_loss: 2.4348 - val_acc: 0.5500\n",
      "Epoch 173/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.3886e-04 - acc: 1.0000 - val_loss: 2.4374 - val_acc: 0.5500\n",
      "Epoch 174/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.4413 - val_acc: 0.5500\n",
      "Epoch 175/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.7942e-04 - acc: 1.0000 - val_loss: 2.4452 - val_acc: 0.5500\n",
      "Epoch 176/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.8917e-04 - acc: 1.0000 - val_loss: 2.4495 - val_acc: 0.5500\n",
      "Epoch 177/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.2512e-04 - acc: 1.0000 - val_loss: 2.4530 - val_acc: 0.5500\n",
      "Epoch 178/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.4585 - val_acc: 0.5000\n",
      "Epoch 179/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.9582e-04 - acc: 1.0000 - val_loss: 2.4633 - val_acc: 0.5000\n",
      "Epoch 180/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.8317e-04 - acc: 1.0000 - val_loss: 2.4634 - val_acc: 0.5000\n",
      "Epoch 181/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.5129e-04 - acc: 1.0000 - val_loss: 2.4622 - val_acc: 0.5000\n",
      "Epoch 182/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.2099e-04 - acc: 1.0000 - val_loss: 2.4627 - val_acc: 0.5000\n",
      "Epoch 183/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.1702e-04 - acc: 1.0000 - val_loss: 2.4638 - val_acc: 0.5500\n",
      "Epoch 184/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.5295e-04 - acc: 1.0000 - val_loss: 2.4656 - val_acc: 0.5500\n",
      "Epoch 185/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.4700 - val_acc: 0.5500\n",
      "Epoch 186/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.6548e-04 - acc: 1.0000 - val_loss: 2.4718 - val_acc: 0.5500\n",
      "Epoch 187/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.2497e-04 - acc: 1.0000 - val_loss: 2.4783 - val_acc: 0.5500\n",
      "Epoch 188/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.5813e-04 - acc: 1.0000 - val_loss: 2.4831 - val_acc: 0.5500\n",
      "Epoch 189/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.0480e-04 - acc: 1.0000 - val_loss: 2.4871 - val_acc: 0.5500\n",
      "Epoch 190/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.3959e-04 - acc: 1.0000 - val_loss: 2.4905 - val_acc: 0.5500\n",
      "Epoch 191/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3653e-04 - acc: 1.0000 - val_loss: 2.4935 - val_acc: 0.5500\n",
      "Epoch 192/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.1879e-04 - acc: 1.0000 - val_loss: 2.4954 - val_acc: 0.5500\n",
      "Epoch 193/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.4729e-04 - acc: 1.0000 - val_loss: 2.4973 - val_acc: 0.5500\n",
      "Epoch 194/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.7410e-04 - acc: 1.0000 - val_loss: 2.5016 - val_acc: 0.5500\n",
      "Epoch 195/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.6917e-04 - acc: 1.0000 - val_loss: 2.5073 - val_acc: 0.5500\n",
      "Epoch 196/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.7912e-04 - acc: 1.0000 - val_loss: 2.5124 - val_acc: 0.5500\n",
      "Epoch 197/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.5129 - val_acc: 0.5500\n",
      "Epoch 198/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.4817e-04 - acc: 1.0000 - val_loss: 2.5112 - val_acc: 0.5500\n",
      "Epoch 199/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.8847e-04 - acc: 1.0000 - val_loss: 2.5105 - val_acc: 0.5500\n",
      "Epoch 200/200\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.1945e-04 - acc: 1.0000 - val_loss: 2.5101 - val_acc: 0.5500\n",
      "Test loss: 2.5101077556610107\n",
      "Test accuracy: 0.550000011920929\n",
      "Train on 40 samples, validate on 20 samples\n",
      "Epoch 1/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.6866 - acc: 0.6000 - val_loss: 0.7833 - val_acc: 0.5000\n",
      "Epoch 2/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.0667 - acc: 0.5000 - val_loss: 1.3207 - val_acc: 0.5000\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 1.2818 - acc: 0.5000 - val_loss: 0.7289 - val_acc: 0.4000\n",
      "Epoch 4/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.7751 - acc: 0.5750 - val_loss: 0.6858 - val_acc: 0.5000\n",
      "Epoch 5/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5309 - acc: 0.7250 - val_loss: 0.8432 - val_acc: 0.5000\n",
      "Epoch 6/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.5109 - acc: 0.7250 - val_loss: 0.8288 - val_acc: 0.5500\n",
      "Epoch 7/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4694 - acc: 0.7250 - val_loss: 0.9041 - val_acc: 0.4000\n",
      "Epoch 8/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3939 - acc: 0.8000 - val_loss: 0.7504 - val_acc: 0.4500\n",
      "Epoch 9/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3509 - acc: 0.8500 - val_loss: 0.8338 - val_acc: 0.6000\n",
      "Epoch 10/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.2446 - acc: 0.9000 - val_loss: 1.1080 - val_acc: 0.4500\n",
      "Epoch 11/300\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.3160 - acc: 0.812 - 0s 1ms/step - loss: 0.3385 - acc: 0.8500 - val_loss: 1.1358 - val_acc: 0.5000\n",
      "Epoch 12/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1820 - acc: 1.0000 - val_loss: 1.1538 - val_acc: 0.4000\n",
      "Epoch 13/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.3865 - acc: 0.8250 - val_loss: 0.9563 - val_acc: 0.5000\n",
      "Epoch 14/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.1263 - acc: 0.9500 - val_loss: 1.2004 - val_acc: 0.5000\n",
      "Epoch 15/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0891 - acc: 1.0000 - val_loss: 1.3386 - val_acc: 0.5000\n",
      "Epoch 16/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0800 - acc: 0.9750 - val_loss: 1.3769 - val_acc: 0.4500\n",
      "Epoch 17/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0534 - acc: 0.9750 - val_loss: 1.3345 - val_acc: 0.4500\n",
      "Epoch 18/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0335 - acc: 1.0000 - val_loss: 1.3397 - val_acc: 0.5000\n",
      "Epoch 19/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0428 - acc: 1.0000 - val_loss: 1.4214 - val_acc: 0.5000\n",
      "Epoch 20/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0244 - acc: 1.0000 - val_loss: 1.5005 - val_acc: 0.4500\n",
      "Epoch 21/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0164 - acc: 1.0000 - val_loss: 1.4789 - val_acc: 0.4500\n",
      "Epoch 22/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 1.4516 - val_acc: 0.4500\n",
      "Epoch 23/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 1.4642 - val_acc: 0.4500\n",
      "Epoch 24/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 1.5289 - val_acc: 0.4500\n",
      "Epoch 25/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0147 - acc: 1.0000 - val_loss: 1.5588 - val_acc: 0.4500\n",
      "Epoch 26/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 1.5924 - val_acc: 0.4500\n",
      "Epoch 27/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 1.6527 - val_acc: 0.4500\n",
      "Epoch 28/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 1.7094 - val_acc: 0.5000\n",
      "Epoch 29/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 1.7282 - val_acc: 0.5000\n",
      "Epoch 30/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 1.7378 - val_acc: 0.5000\n",
      "Epoch 31/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.7482 - val_acc: 0.5000\n",
      "Epoch 32/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 1.7495 - val_acc: 0.5000\n",
      "Epoch 33/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.7392 - val_acc: 0.5000\n",
      "Epoch 34/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.7339 - val_acc: 0.5000\n",
      "Epoch 35/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 1.7385 - val_acc: 0.5000\n",
      "Epoch 36/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.7452 - val_acc: 0.5000\n",
      "Epoch 37/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.7441 - val_acc: 0.5000\n",
      "Epoch 38/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.7475 - val_acc: 0.5000\n",
      "Epoch 39/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.7554 - val_acc: 0.5000\n",
      "Epoch 40/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.7622 - val_acc: 0.5000\n",
      "Epoch 41/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 1.7714 - val_acc: 0.5000\n",
      "Epoch 42/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 1.7674 - val_acc: 0.5000\n",
      "Epoch 43/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.7706 - val_acc: 0.5000\n",
      "Epoch 44/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 1.7902 - val_acc: 0.5000\n",
      "Epoch 45/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 1.8025 - val_acc: 0.5000\n",
      "Epoch 46/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.8077 - val_acc: 0.5000\n",
      "Epoch 47/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 1.8148 - val_acc: 0.5000\n",
      "Epoch 48/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.8337 - val_acc: 0.5000\n",
      "Epoch 49/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.8552 - val_acc: 0.5000\n",
      "Epoch 50/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.8765 - val_acc: 0.5000\n",
      "Epoch 51/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.8933 - val_acc: 0.5000\n",
      "Epoch 52/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.9076 - val_acc: 0.5000\n",
      "Epoch 53/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 1.9270 - val_acc: 0.5000\n",
      "Epoch 54/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.9473 - val_acc: 0.5000\n",
      "Epoch 55/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.9750 - val_acc: 0.5000\n",
      "Epoch 56/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.9909 - val_acc: 0.5000\n",
      "Epoch 57/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.0012 - val_acc: 0.5000\n",
      "Epoch 58/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.0065 - val_acc: 0.5000\n",
      "Epoch 59/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 2.0219 - val_acc: 0.5000\n",
      "Epoch 60/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.0394 - val_acc: 0.5000\n",
      "Epoch 61/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.0446 - val_acc: 0.5000\n",
      "Epoch 62/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.0331 - val_acc: 0.5000\n",
      "Epoch 63/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.0248 - val_acc: 0.5000\n",
      "Epoch 64/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.0206 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.0200 - val_acc: 0.5000\n",
      "Epoch 66/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 2.0233 - val_acc: 0.5000\n",
      "Epoch 67/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.0334 - val_acc: 0.5000\n",
      "Epoch 68/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 2.0389 - val_acc: 0.5000\n",
      "Epoch 69/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.0500 - val_acc: 0.5000\n",
      "Epoch 70/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.0644 - val_acc: 0.5000\n",
      "Epoch 71/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.1924e-04 - acc: 1.0000 - val_loss: 2.0763 - val_acc: 0.5000\n",
      "Epoch 72/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.4938e-04 - acc: 1.0000 - val_loss: 2.0860 - val_acc: 0.5000\n",
      "Epoch 73/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.6492e-04 - acc: 1.0000 - val_loss: 2.0947 - val_acc: 0.5000\n",
      "Epoch 74/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 2.0946 - val_acc: 0.5000\n",
      "Epoch 75/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.7995e-04 - acc: 1.0000 - val_loss: 2.0864 - val_acc: 0.5000\n",
      "Epoch 76/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.4804e-04 - acc: 1.0000 - val_loss: 2.0784 - val_acc: 0.5000\n",
      "Epoch 77/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.0741 - val_acc: 0.5000\n",
      "Epoch 78/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.0703 - val_acc: 0.5000\n",
      "Epoch 79/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.0715 - val_acc: 0.5000\n",
      "Epoch 80/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.8062e-04 - acc: 1.0000 - val_loss: 2.0806 - val_acc: 0.5000\n",
      "Epoch 81/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.0917 - val_acc: 0.5000\n",
      "Epoch 82/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 2.1018 - val_acc: 0.5000\n",
      "Epoch 83/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 2.1147 - val_acc: 0.5000\n",
      "Epoch 84/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.1302 - val_acc: 0.5000\n",
      "Epoch 85/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.0676e-04 - acc: 1.0000 - val_loss: 2.1435 - val_acc: 0.5000\n",
      "Epoch 86/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.1599 - val_acc: 0.5000\n",
      "Epoch 87/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 2.1713 - val_acc: 0.5000\n",
      "Epoch 88/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.1714 - val_acc: 0.5000\n",
      "Epoch 89/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.6904e-04 - acc: 1.0000 - val_loss: 2.1702 - val_acc: 0.5000\n",
      "Epoch 90/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.1702 - val_acc: 0.5000\n",
      "Epoch 91/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.1719 - val_acc: 0.5000\n",
      "Epoch 92/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.3316e-04 - acc: 1.0000 - val_loss: 2.1746 - val_acc: 0.5000\n",
      "Epoch 93/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.1772 - val_acc: 0.5000\n",
      "Epoch 94/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.1741e-04 - acc: 1.0000 - val_loss: 2.1797 - val_acc: 0.5000\n",
      "Epoch 95/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.4545e-04 - acc: 1.0000 - val_loss: 2.1811 - val_acc: 0.5000\n",
      "Epoch 96/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.1849 - val_acc: 0.5000\n",
      "Epoch 97/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.5959e-04 - acc: 1.0000 - val_loss: 2.1888 - val_acc: 0.5000\n",
      "Epoch 98/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.4304e-04 - acc: 1.0000 - val_loss: 2.1922 - val_acc: 0.5000\n",
      "Epoch 99/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.1975 - val_acc: 0.5000\n",
      "Epoch 100/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.2033 - val_acc: 0.5000\n",
      "Epoch 101/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.1974 - val_acc: 0.5000\n",
      "Epoch 102/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.9886e-04 - acc: 1.0000 - val_loss: 2.1958 - val_acc: 0.5000\n",
      "Epoch 103/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.2498e-04 - acc: 1.0000 - val_loss: 2.1963 - val_acc: 0.5000\n",
      "Epoch 104/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.1972 - val_acc: 0.5000\n",
      "Epoch 105/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.7095e-04 - acc: 1.0000 - val_loss: 2.1989 - val_acc: 0.5000\n",
      "Epoch 106/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.9147e-04 - acc: 1.0000 - val_loss: 2.2026 - val_acc: 0.5000\n",
      "Epoch 107/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.5980e-04 - acc: 1.0000 - val_loss: 2.2088 - val_acc: 0.5000\n",
      "Epoch 108/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.2157 - val_acc: 0.5000\n",
      "Epoch 109/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.0697e-04 - acc: 1.0000 - val_loss: 2.2199 - val_acc: 0.5000\n",
      "Epoch 110/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.2698e-04 - acc: 1.0000 - val_loss: 2.2237 - val_acc: 0.5000\n",
      "Epoch 111/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.5049e-04 - acc: 1.0000 - val_loss: 2.2283 - val_acc: 0.5000\n",
      "Epoch 112/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.6283e-04 - acc: 1.0000 - val_loss: 2.2340 - val_acc: 0.5000\n",
      "Epoch 113/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.2253e-04 - acc: 1.0000 - val_loss: 2.2400 - val_acc: 0.5000\n",
      "Epoch 114/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.2437 - val_acc: 0.5000\n",
      "Epoch 115/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.2458 - val_acc: 0.5000\n",
      "Epoch 116/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.8782e-04 - acc: 1.0000 - val_loss: 2.2537 - val_acc: 0.5000\n",
      "Epoch 117/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.4815e-04 - acc: 1.0000 - val_loss: 2.2586 - val_acc: 0.5000\n",
      "Epoch 118/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.9213e-04 - acc: 1.0000 - val_loss: 2.2604 - val_acc: 0.5000\n",
      "Epoch 119/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.2640 - val_acc: 0.5000\n",
      "Epoch 120/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.2691 - val_acc: 0.5000\n",
      "Epoch 121/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.2960e-04 - acc: 1.0000 - val_loss: 2.2739 - val_acc: 0.5000\n",
      "Epoch 122/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.5078e-04 - acc: 1.0000 - val_loss: 2.2759 - val_acc: 0.5000\n",
      "Epoch 123/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.2742 - val_acc: 0.5000\n",
      "Epoch 124/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.5471e-04 - acc: 1.0000 - val_loss: 2.2667 - val_acc: 0.5000\n",
      "Epoch 125/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 2.2662 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.1316e-04 - acc: 1.0000 - val_loss: 2.2792 - val_acc: 0.5000\n",
      "Epoch 127/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.2485e-04 - acc: 1.0000 - val_loss: 2.2872 - val_acc: 0.5000\n",
      "Epoch 128/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.2973 - val_acc: 0.5000\n",
      "Epoch 129/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 2.3035 - val_acc: 0.5000\n",
      "Epoch 130/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.8290e-04 - acc: 1.0000 - val_loss: 2.3114 - val_acc: 0.5000\n",
      "Epoch 131/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 2.3363 - val_acc: 0.5000\n",
      "Epoch 132/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.6276e-04 - acc: 1.0000 - val_loss: 2.3585 - val_acc: 0.5000\n",
      "Epoch 133/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.8880e-04 - acc: 1.0000 - val_loss: 2.3801 - val_acc: 0.5000\n",
      "Epoch 134/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 2.4012 - val_acc: 0.5000\n",
      "Epoch 135/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.2117e-04 - acc: 1.0000 - val_loss: 2.4172 - val_acc: 0.5000\n",
      "Epoch 136/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.3665e-04 - acc: 1.0000 - val_loss: 2.4280 - val_acc: 0.5000\n",
      "Epoch 137/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.7100e-04 - acc: 1.0000 - val_loss: 2.4341 - val_acc: 0.5000\n",
      "Epoch 138/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 2.4424 - val_acc: 0.5000\n",
      "Epoch 139/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.5372e-04 - acc: 1.0000 - val_loss: 2.4493 - val_acc: 0.5000\n",
      "Epoch 140/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.4654 - val_acc: 0.5000\n",
      "Epoch 141/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.4757 - val_acc: 0.5000\n",
      "Epoch 142/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.5936e-04 - acc: 1.0000 - val_loss: 2.4772 - val_acc: 0.5000\n",
      "Epoch 143/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.4747 - val_acc: 0.5000\n",
      "Epoch 144/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.1432e-04 - acc: 1.0000 - val_loss: 2.4732 - val_acc: 0.5000\n",
      "Epoch 145/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.8483e-04 - acc: 1.0000 - val_loss: 2.4722 - val_acc: 0.5000\n",
      "Epoch 146/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.9225e-04 - acc: 1.0000 - val_loss: 2.4704 - val_acc: 0.5000\n",
      "Epoch 147/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.4005e-04 - acc: 1.0000 - val_loss: 2.4653 - val_acc: 0.5000\n",
      "Epoch 148/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.6352e-04 - acc: 1.0000 - val_loss: 2.4608 - val_acc: 0.5000\n",
      "Epoch 149/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3597e-04 - acc: 1.0000 - val_loss: 2.4594 - val_acc: 0.5000\n",
      "Epoch 150/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.2865e-04 - acc: 1.0000 - val_loss: 2.4614 - val_acc: 0.5000\n",
      "Epoch 151/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.4823e-04 - acc: 1.0000 - val_loss: 2.4632 - val_acc: 0.5000\n",
      "Epoch 152/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.4110e-04 - acc: 1.0000 - val_loss: 2.4652 - val_acc: 0.5000\n",
      "Epoch 153/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.3110e-04 - acc: 1.0000 - val_loss: 2.4669 - val_acc: 0.5000\n",
      "Epoch 154/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.1532e-04 - acc: 1.0000 - val_loss: 2.4671 - val_acc: 0.5000\n",
      "Epoch 155/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.7330e-04 - acc: 1.0000 - val_loss: 2.4666 - val_acc: 0.5000\n",
      "Epoch 156/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.3381e-04 - acc: 1.0000 - val_loss: 2.4675 - val_acc: 0.5000\n",
      "Epoch 157/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.5650e-04 - acc: 1.0000 - val_loss: 2.4681 - val_acc: 0.5000\n",
      "Epoch 158/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.8343e-04 - acc: 1.0000 - val_loss: 2.4679 - val_acc: 0.5000\n",
      "Epoch 159/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.6057e-04 - acc: 1.0000 - val_loss: 2.4670 - val_acc: 0.5000\n",
      "Epoch 160/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.0715e-04 - acc: 1.0000 - val_loss: 2.4673 - val_acc: 0.5000\n",
      "Epoch 161/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.5385e-04 - acc: 1.0000 - val_loss: 2.4689 - val_acc: 0.5000\n",
      "Epoch 162/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.7659e-04 - acc: 1.0000 - val_loss: 2.4706 - val_acc: 0.5000\n",
      "Epoch 163/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.1565e-04 - acc: 1.0000 - val_loss: 2.4701 - val_acc: 0.5000\n",
      "Epoch 164/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.5039e-04 - acc: 1.0000 - val_loss: 2.4701 - val_acc: 0.5000\n",
      "Epoch 165/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.9111e-04 - acc: 1.0000 - val_loss: 2.4730 - val_acc: 0.5000\n",
      "Epoch 166/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3793e-04 - acc: 1.0000 - val_loss: 2.4765 - val_acc: 0.5000\n",
      "Epoch 167/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.5490e-04 - acc: 1.0000 - val_loss: 2.4792 - val_acc: 0.5000\n",
      "Epoch 168/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.4809e-04 - acc: 1.0000 - val_loss: 2.4798 - val_acc: 0.5000\n",
      "Epoch 169/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.1894e-04 - acc: 1.0000 - val_loss: 2.4809 - val_acc: 0.5000\n",
      "Epoch 170/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.8141e-04 - acc: 1.0000 - val_loss: 2.4827 - val_acc: 0.5000\n",
      "Epoch 171/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.8531e-04 - acc: 1.0000 - val_loss: 2.4855 - val_acc: 0.5000\n",
      "Epoch 172/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.5808e-04 - acc: 1.0000 - val_loss: 2.4893 - val_acc: 0.5000\n",
      "Epoch 173/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.7727e-04 - acc: 1.0000 - val_loss: 2.4917 - val_acc: 0.5000\n",
      "Epoch 174/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.2392e-04 - acc: 1.0000 - val_loss: 2.4940 - val_acc: 0.5000\n",
      "Epoch 175/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.1170e-04 - acc: 1.0000 - val_loss: 2.4936 - val_acc: 0.5000\n",
      "Epoch 176/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.3307e-04 - acc: 1.0000 - val_loss: 2.4952 - val_acc: 0.5000\n",
      "Epoch 177/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.2417e-04 - acc: 1.0000 - val_loss: 2.5013 - val_acc: 0.5000\n",
      "Epoch 178/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.1678e-04 - acc: 1.0000 - val_loss: 2.5067 - val_acc: 0.5000\n",
      "Epoch 179/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.5553e-04 - acc: 1.0000 - val_loss: 2.5096 - val_acc: 0.5000\n",
      "Epoch 180/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.3981e-04 - acc: 1.0000 - val_loss: 2.5123 - val_acc: 0.5000\n",
      "Epoch 181/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3119e-04 - acc: 1.0000 - val_loss: 2.5127 - val_acc: 0.5000\n",
      "Epoch 182/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.5100 - val_acc: 0.5000\n",
      "Epoch 183/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.9062e-04 - acc: 1.0000 - val_loss: 2.5072 - val_acc: 0.5000\n",
      "Epoch 184/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.0151e-04 - acc: 1.0000 - val_loss: 2.5035 - val_acc: 0.5000\n",
      "Epoch 185/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.7165e-04 - acc: 1.0000 - val_loss: 2.4985 - val_acc: 0.5000\n",
      "Epoch 186/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 2.9323e-04 - acc: 1.0000 - val_loss: 2.4952 - val_acc: 0.5000\n",
      "Epoch 187/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.2619e-04 - acc: 1.0000 - val_loss: 2.4889 - val_acc: 0.5000\n",
      "Epoch 188/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 2.4932 - val_acc: 0.5000\n",
      "Epoch 189/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.3039e-04 - acc: 1.0000 - val_loss: 2.5010 - val_acc: 0.5000\n",
      "Epoch 190/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.6093e-04 - acc: 1.0000 - val_loss: 2.5054 - val_acc: 0.5000\n",
      "Epoch 191/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.9186e-04 - acc: 1.0000 - val_loss: 2.5057 - val_acc: 0.5000\n",
      "Epoch 192/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.0267e-04 - acc: 1.0000 - val_loss: 2.5068 - val_acc: 0.5000\n",
      "Epoch 193/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.1210e-04 - acc: 1.0000 - val_loss: 2.5074 - val_acc: 0.5000\n",
      "Epoch 194/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.4306e-04 - acc: 1.0000 - val_loss: 2.5117 - val_acc: 0.5000\n",
      "Epoch 195/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.5145 - val_acc: 0.5000\n",
      "Epoch 196/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.9040e-04 - acc: 1.0000 - val_loss: 2.5177 - val_acc: 0.5000\n",
      "Epoch 197/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.5312 - val_acc: 0.5000\n",
      "Epoch 198/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.1460e-04 - acc: 1.0000 - val_loss: 2.5557 - val_acc: 0.5000\n",
      "Epoch 199/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.2093e-04 - acc: 1.0000 - val_loss: 2.5724 - val_acc: 0.5000\n",
      "Epoch 200/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.9025e-04 - acc: 1.0000 - val_loss: 2.5846 - val_acc: 0.5000\n",
      "Epoch 201/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.7669e-04 - acc: 1.0000 - val_loss: 2.5927 - val_acc: 0.5000\n",
      "Epoch 202/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.9817e-04 - acc: 1.0000 - val_loss: 2.5973 - val_acc: 0.5000\n",
      "Epoch 203/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.6992e-04 - acc: 1.0000 - val_loss: 2.5971 - val_acc: 0.5000\n",
      "Epoch 204/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.5629e-04 - acc: 1.0000 - val_loss: 2.5967 - val_acc: 0.5000\n",
      "Epoch 205/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3639e-04 - acc: 1.0000 - val_loss: 2.5949 - val_acc: 0.5000\n",
      "Epoch 206/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3542e-04 - acc: 1.0000 - val_loss: 2.5919 - val_acc: 0.5000\n",
      "Epoch 207/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.6754e-04 - acc: 1.0000 - val_loss: 2.5857 - val_acc: 0.5000\n",
      "Epoch 208/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.9563e-04 - acc: 1.0000 - val_loss: 2.5819 - val_acc: 0.5000\n",
      "Epoch 209/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.8875e-04 - acc: 1.0000 - val_loss: 2.5769 - val_acc: 0.5000\n",
      "Epoch 210/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.2103e-04 - acc: 1.0000 - val_loss: 2.5741 - val_acc: 0.5000\n",
      "Epoch 211/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.0455e-04 - acc: 1.0000 - val_loss: 2.5720 - val_acc: 0.5000\n",
      "Epoch 212/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3798e-04 - acc: 1.0000 - val_loss: 2.5709 - val_acc: 0.5000\n",
      "Epoch 213/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.6627e-04 - acc: 1.0000 - val_loss: 2.5710 - val_acc: 0.5000\n",
      "Epoch 214/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.1565e-04 - acc: 1.0000 - val_loss: 2.5771 - val_acc: 0.5000\n",
      "Epoch 215/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.3836e-04 - acc: 1.0000 - val_loss: 2.5824 - val_acc: 0.5000\n",
      "Epoch 216/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.8148e-04 - acc: 1.0000 - val_loss: 2.5811 - val_acc: 0.5000\n",
      "Epoch 217/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.1797e-04 - acc: 1.0000 - val_loss: 2.5808 - val_acc: 0.5000\n",
      "Epoch 218/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.2565e-04 - acc: 1.0000 - val_loss: 2.5820 - val_acc: 0.5000\n",
      "Epoch 219/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.6250e-04 - acc: 1.0000 - val_loss: 2.5840 - val_acc: 0.5000\n",
      "Epoch 220/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.0875e-04 - acc: 1.0000 - val_loss: 2.5860 - val_acc: 0.5000\n",
      "Epoch 221/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.6063e-04 - acc: 1.0000 - val_loss: 2.5854 - val_acc: 0.5000\n",
      "Epoch 222/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.8369e-04 - acc: 1.0000 - val_loss: 2.5845 - val_acc: 0.5000\n",
      "Epoch 223/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.3914e-04 - acc: 1.0000 - val_loss: 2.5838 - val_acc: 0.5000\n",
      "Epoch 224/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.9891e-04 - acc: 1.0000 - val_loss: 2.5838 - val_acc: 0.5000\n",
      "Epoch 225/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.1893e-04 - acc: 1.0000 - val_loss: 2.5854 - val_acc: 0.5000\n",
      "Epoch 226/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.7737e-04 - acc: 1.0000 - val_loss: 2.5881 - val_acc: 0.5000\n",
      "Epoch 227/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.7294e-04 - acc: 1.0000 - val_loss: 2.5933 - val_acc: 0.5000\n",
      "Epoch 228/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.8253e-04 - acc: 1.0000 - val_loss: 2.6035 - val_acc: 0.5000\n",
      "Epoch 229/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.9345e-04 - acc: 1.0000 - val_loss: 2.6128 - val_acc: 0.5000\n",
      "Epoch 230/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.3583e-04 - acc: 1.0000 - val_loss: 2.6195 - val_acc: 0.5000\n",
      "Epoch 231/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.6102e-04 - acc: 1.0000 - val_loss: 2.6246 - val_acc: 0.5000\n",
      "Epoch 232/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.3085e-05 - acc: 1.0000 - val_loss: 2.6280 - val_acc: 0.5000\n",
      "Epoch 233/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.0476e-04 - acc: 1.0000 - val_loss: 2.6295 - val_acc: 0.5000\n",
      "Epoch 234/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.4875e-04 - acc: 1.0000 - val_loss: 2.6330 - val_acc: 0.5000\n",
      "Epoch 235/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.2237e-04 - acc: 1.0000 - val_loss: 2.6369 - val_acc: 0.5000\n",
      "Epoch 236/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.5390e-04 - acc: 1.0000 - val_loss: 2.6408 - val_acc: 0.5000\n",
      "Epoch 237/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.8115e-04 - acc: 1.0000 - val_loss: 2.6441 - val_acc: 0.5000\n",
      "Epoch 238/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.4895e-04 - acc: 1.0000 - val_loss: 2.6472 - val_acc: 0.5000\n",
      "Epoch 239/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.4754e-04 - acc: 1.0000 - val_loss: 2.6491 - val_acc: 0.5000\n",
      "Epoch 240/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.8178e-04 - acc: 1.0000 - val_loss: 2.6484 - val_acc: 0.5000\n",
      "Epoch 241/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.0161e-04 - acc: 1.0000 - val_loss: 2.6454 - val_acc: 0.5000\n",
      "Epoch 242/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.9545e-04 - acc: 1.0000 - val_loss: 2.6438 - val_acc: 0.5000\n",
      "Epoch 243/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.2200e-04 - acc: 1.0000 - val_loss: 2.6437 - val_acc: 0.5000\n",
      "Epoch 244/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.7157e-04 - acc: 1.0000 - val_loss: 2.6438 - val_acc: 0.5000\n",
      "Epoch 245/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.9506e-04 - acc: 1.0000 - val_loss: 2.6435 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.8183e-04 - acc: 1.0000 - val_loss: 2.6449 - val_acc: 0.5000\n",
      "Epoch 247/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.8005e-04 - acc: 1.0000 - val_loss: 2.6497 - val_acc: 0.5000\n",
      "Epoch 248/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.6070e-04 - acc: 1.0000 - val_loss: 2.6535 - val_acc: 0.5000\n",
      "Epoch 249/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.4871e-04 - acc: 1.0000 - val_loss: 2.6535 - val_acc: 0.5000\n",
      "Epoch 250/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.7771e-04 - acc: 1.0000 - val_loss: 2.6520 - val_acc: 0.5000\n",
      "Epoch 251/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.3603e-04 - acc: 1.0000 - val_loss: 2.6481 - val_acc: 0.5000\n",
      "Epoch 252/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.4505e-04 - acc: 1.0000 - val_loss: 2.6449 - val_acc: 0.5000\n",
      "Epoch 253/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.8084e-04 - acc: 1.0000 - val_loss: 2.6421 - val_acc: 0.5000\n",
      "Epoch 254/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.6686e-04 - acc: 1.0000 - val_loss: 2.6394 - val_acc: 0.5000\n",
      "Epoch 255/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.1939e-04 - acc: 1.0000 - val_loss: 2.6399 - val_acc: 0.5000\n",
      "Epoch 256/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.3806e-04 - acc: 1.0000 - val_loss: 2.6420 - val_acc: 0.5000\n",
      "Epoch 257/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.6698e-04 - acc: 1.0000 - val_loss: 2.6447 - val_acc: 0.5000\n",
      "Epoch 258/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.2195e-04 - acc: 1.0000 - val_loss: 2.6476 - val_acc: 0.5000\n",
      "Epoch 259/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.7044e-04 - acc: 1.0000 - val_loss: 2.6479 - val_acc: 0.5000\n",
      "Epoch 260/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.2979e-04 - acc: 1.0000 - val_loss: 2.6482 - val_acc: 0.5000\n",
      "Epoch 261/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.5634e-04 - acc: 1.0000 - val_loss: 2.6489 - val_acc: 0.5000\n",
      "Epoch 262/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.7866e-04 - acc: 1.0000 - val_loss: 2.6491 - val_acc: 0.5000\n",
      "Epoch 263/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.7581e-04 - acc: 1.0000 - val_loss: 2.6484 - val_acc: 0.5000\n",
      "Epoch 264/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.6417 - val_acc: 0.5000\n",
      "Epoch 265/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.2558e-04 - acc: 1.0000 - val_loss: 2.6371 - val_acc: 0.5000\n",
      "Epoch 266/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 8.0908e-05 - acc: 1.0000 - val_loss: 2.6345 - val_acc: 0.5000\n",
      "Epoch 267/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.5919e-04 - acc: 1.0000 - val_loss: 2.6336 - val_acc: 0.5000\n",
      "Epoch 268/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 9.0461e-04 - acc: 1.0000 - val_loss: 2.6321 - val_acc: 0.5000\n",
      "Epoch 269/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.3169e-04 - acc: 1.0000 - val_loss: 2.6313 - val_acc: 0.5000\n",
      "Epoch 270/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.6502e-04 - acc: 1.0000 - val_loss: 2.6313 - val_acc: 0.5000\n",
      "Epoch 271/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.0735e-04 - acc: 1.0000 - val_loss: 2.6328 - val_acc: 0.5000\n",
      "Epoch 272/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.9421e-04 - acc: 1.0000 - val_loss: 2.6361 - val_acc: 0.5000\n",
      "Epoch 273/300\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.9804e-04 - acc: 1.000 - 0s 1ms/step - loss: 5.0998e-04 - acc: 1.0000 - val_loss: 2.6382 - val_acc: 0.5000\n",
      "Epoch 274/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.6490e-04 - acc: 1.0000 - val_loss: 2.6402 - val_acc: 0.5000\n",
      "Epoch 275/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.8314e-04 - acc: 1.0000 - val_loss: 2.6411 - val_acc: 0.5000\n",
      "Epoch 276/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.0157e-04 - acc: 1.0000 - val_loss: 2.6420 - val_acc: 0.5000\n",
      "Epoch 277/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 2.6477 - val_acc: 0.5000\n",
      "Epoch 278/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.7524e-04 - acc: 1.0000 - val_loss: 2.6546 - val_acc: 0.5000\n",
      "Epoch 279/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.6639 - val_acc: 0.5000\n",
      "Epoch 280/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.1300e-04 - acc: 1.0000 - val_loss: 2.6783 - val_acc: 0.5000\n",
      "Epoch 281/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.5542e-04 - acc: 1.0000 - val_loss: 2.6881 - val_acc: 0.5000\n",
      "Epoch 282/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.0187e-04 - acc: 1.0000 - val_loss: 2.6955 - val_acc: 0.5000\n",
      "Epoch 283/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 5.3256e-04 - acc: 1.0000 - val_loss: 2.6995 - val_acc: 0.5000\n",
      "Epoch 284/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.6885e-04 - acc: 1.0000 - val_loss: 2.7008 - val_acc: 0.5000\n",
      "Epoch 285/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.7519e-04 - acc: 1.0000 - val_loss: 2.6991 - val_acc: 0.5000\n",
      "Epoch 286/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.8944e-04 - acc: 1.0000 - val_loss: 2.6960 - val_acc: 0.5000\n",
      "Epoch 287/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.5694e-04 - acc: 1.0000 - val_loss: 2.6920 - val_acc: 0.5000\n",
      "Epoch 288/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.6614e-04 - acc: 1.0000 - val_loss: 2.6882 - val_acc: 0.5000\n",
      "Epoch 289/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 4.1035e-04 - acc: 1.0000 - val_loss: 2.6846 - val_acc: 0.5000\n",
      "Epoch 290/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.0074e-04 - acc: 1.0000 - val_loss: 2.6813 - val_acc: 0.5000\n",
      "Epoch 291/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.0831e-04 - acc: 1.0000 - val_loss: 2.6794 - val_acc: 0.5000\n",
      "Epoch 292/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 2.4288e-04 - acc: 1.0000 - val_loss: 2.6785 - val_acc: 0.5000\n",
      "Epoch 293/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.0080e-04 - acc: 1.0000 - val_loss: 2.6755 - val_acc: 0.5000\n",
      "Epoch 294/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 2.6533 - val_acc: 0.5000\n",
      "Epoch 295/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 3.4388e-04 - acc: 1.0000 - val_loss: 2.6386 - val_acc: 0.5000\n",
      "Epoch 296/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.6434 - val_acc: 0.5000\n",
      "Epoch 297/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 6.2945e-04 - acc: 1.0000 - val_loss: 2.6450 - val_acc: 0.5000\n",
      "Epoch 298/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.9059e-04 - acc: 1.0000 - val_loss: 2.6475 - val_acc: 0.5000\n",
      "Epoch 299/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 1.1419e-04 - acc: 1.0000 - val_loss: 2.6507 - val_acc: 0.5000\n",
      "Epoch 300/300\n",
      "40/40 [==============================] - 0s 1ms/step - loss: 7.1671e-05 - acc: 1.0000 - val_loss: 2.6538 - val_acc: 0.5000\n",
      "Test loss: 2.6537821292877197\n",
      "Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for n_epoch in num_steps:\n",
    "    train_history = model.fit(x=X_train, y=y_train,\n",
    "                            batch_size= 16,\n",
    "                            epochs=n_epoch,\n",
    "                            verbose=1,\n",
    "                            validation_data=(X_test, y_test)\n",
    "                             )\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    reset_model(model, Wsave)\n",
    "    result.append(train_history)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using the trainned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " gato!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '/Users/filipetheodoro/Ai/DeepLearning/Deep Learning course - Capstone Project/teste.jpeg'\n",
    "test_image = cv2.imread(path)\n",
    "im_resize = cv2.resize(test_image,img_shape, interpolation=cv2.INTER_CUBIC)\n",
    "image_stack = []\n",
    "image_stack.append(im_resize)\n",
    "# image_stack.append(X_train[30])\n",
    "y_test_pred = model.predict_classes(np.array(image_stack), verbose=0)\n",
    "\n",
    "if y_test_pred[0] == 0:\n",
    "    print(\" cachorro!\")\n",
    "else:\n",
    "    print(\" gato!\")\n",
    "    \n",
    "fig1 = plt.figure() \n",
    "ax1 = fig1.add_subplot(2,2,1) \n",
    "ax1.imshow(image_stack[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_params():\n",
    "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
    "\n",
    "def restore_model_params(model_params):\n",
    "    gvar_names = list(model_params.keys())\n",
    "    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                  for gvar_name in gvar_names}\n",
    "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d44f22dde2d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mxentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_softmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxentropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   2061\u001b[0m       raise ValueError(\"Rank mismatch: Rank of labels (received %s) should \"\n\u001b[1;32m   2062\u001b[0m                        \u001b[0;34m\"equal rank of logits minus 1 (received %s).\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m                        (labels_static_shape.ndims, logits.get_shape().ndims))\n\u001b[0m\u001b[1;32m   2064\u001b[0m     if (static_shapes_fully_defined and\n\u001b[1;32m   2065\u001b[0m         labels_static_shape != logits.get_shape()[:-1]):\n",
      "\u001b[0;31mValueError\u001b[0m: Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2)."
     ]
    }
   ],
   "source": [
    "height = 32\n",
    "width = 32\n",
    "channels = 3\n",
    "n_inputs = height * width\n",
    "\n",
    "conv1_fmaps = 32\n",
    "conv1_ksize = 5\n",
    "conv1_stride = 1\n",
    "conv1_pad = \"SAME\"\n",
    "\n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 5\n",
    "conv2_stride = 1\n",
    "conv2_pad = \"SAME\"\n",
    "conv2_dropout_rate = 0.25\n",
    "\n",
    "pool1_fmaps = conv2_fmaps\n",
    "\n",
    "n_fc1 = 32\n",
    "fc1_dropout_rate = 0.4\n",
    "\n",
    "n_outputs = 32\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None, 2], name=\"y\")\n",
    "    training = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.elu, name=\"conv1\")\n",
    "\n",
    "with tf.name_scope(\"pool1\"):\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "#   pool1_flat = tf.reshape(pool1, shape=[-1, pool1_fmaps * 14 * 14])\n",
    "#   pool1_flat_drop = tf.layers.dropout(pool1_flat, conv2_dropout_rate, training=training)\n",
    "\n",
    "conv2 = tf.layers.conv2d(pool1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.elu, name=\"conv2\")\n",
    "\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps * 14 * 14])\n",
    "#         pool3_flat_drop = tf.layers.dropout(pool3_flat, conv2_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.elu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, fc1_dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = [100, 200, 300]\n",
    "batch_size = 50\n",
    "\n",
    "best_loss_val = np.infty\n",
    "check_interval = 500\n",
    "checks_since_last_progress = 0\n",
    "max_checks_without_progress = 20\n",
    "best_model_params = None \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for n_epoch in n_epochs:\n",
    "        print(\"Running model with {} epochs.\".format(n_epoch))\n",
    "        for epoch in range(n_epoch):\n",
    "            for iteration in range(mnist.train.num_examples // batch_size):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "                if iteration % check_interval == 0:\n",
    "                    loss_val = loss.eval(feed_dict={X: mnist.validation.images,\n",
    "                                                    y: mnist.validation.labels})\n",
    "                    if loss_val < best_loss_val:\n",
    "                        best_loss_val = loss_val\n",
    "                        checks_since_last_progress = 0\n",
    "                        best_model_params = get_model_params()\n",
    "                    else:\n",
    "                        checks_since_last_progress += 1\n",
    "            acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_val = accuracy.eval(feed_dict={X: mnist.validation.images,\n",
    "                                               y: mnist.validation.labels})\n",
    "            print(\"Epoch {} of {}, train accuracy: {:.4f}%, valid. accuracy: {:.4f}%, valid. best loss: {:.6f}\".format(\n",
    "                      epoch, n_epoch, acc_train * 100, acc_val * 100, best_loss_val))\n",
    "            if checks_since_last_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "    if best_model_params:\n",
    "        restore_model_params(best_model_params)\n",
    "    acc_test = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                        y: mnist.test.labels})\n",
    "    print(\"Final accuracy on test set:\", acc_test)\n",
    "    save_path = saver.save(sess, \"./my_mnist_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the tensorflow model\n",
    "\n",
    "This section will use the model defined by the student and run the training and evaluation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_tf_random_seed': 1, '_save_checkpoints_secs': 600, '_model_dir': '/tmp/pets_convnet_model', '_keep_checkpoint_max': 5}\n",
      "dense shape (10, 32)\n",
      "logits shape (10, 2)\n",
      "labels shape (10,)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/pets_convnet_model\\model.ckpt-900\n",
      "INFO:tensorflow:Saving checkpoints for 901 into /tmp/pets_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:step = 901, loss = 0.0187773\n",
      "INFO:tensorflow:probabilities = [[ 0.00206337  0.99793661]\n",
      " [ 0.00148379  0.99851626]\n",
      " [ 0.9898901   0.01010988]\n",
      " [ 0.99925309  0.00074691]\n",
      " [ 0.08117108  0.91882885]\n",
      " [ 0.02973635  0.9702636 ]\n",
      " [ 0.99679643  0.00320353]\n",
      " [ 0.02872127  0.97127873]\n",
      " [ 0.0007444   0.9992556 ]\n",
      " [ 0.02505689  0.97494304]]\n",
      "INFO:tensorflow:probabilities = [[ 0.99930084  0.0006992 ]\n",
      " [ 0.99996495  0.00003507]\n",
      " [ 0.00001954  0.99998045]\n",
      " [ 0.0005221   0.99947792]\n",
      " [ 0.80305207  0.19694798]\n",
      " [ 0.00001898  0.99998105]\n",
      " [ 0.97697568  0.0230243 ]\n",
      " [ 0.99939919  0.00060083]\n",
      " [ 0.99928099  0.00071902]\n",
      " [ 0.98675168  0.01324836]] (0.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.7582\n",
      "INFO:tensorflow:step = 1001, loss = 0.0113643 (1.127 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.00488581  0.99511421]\n",
      " [ 0.00160594  0.99839407]\n",
      " [ 0.02687712  0.97312284]\n",
      " [ 0.01502644  0.98497355]\n",
      " [ 0.02739836  0.97260159]\n",
      " [ 0.99983203  0.0001679 ]\n",
      " [ 0.99954319  0.00045685]\n",
      " [ 0.99394035  0.00605966]\n",
      " [ 0.9997161   0.00028384]\n",
      " [ 0.97046012  0.02953982]] (0.497 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.99991453  0.00008551]\n",
      " [ 0.99996197  0.00003803]\n",
      " [ 0.9998945   0.00010553]\n",
      " [ 0.99989223  0.00010778]\n",
      " [ 0.00871439  0.99128562]\n",
      " [ 0.04076979  0.95923018]\n",
      " [ 0.99977583  0.00022422]\n",
      " [ 0.96885085  0.03114913]\n",
      " [ 0.03155375  0.96844625]\n",
      " [ 0.00391518  0.99608481]] (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.7314\n",
      "INFO:tensorflow:step = 1101, loss = 0.014275 (1.082 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.00433608  0.99566394]\n",
      " [ 0.96065736  0.03934268]\n",
      " [ 0.99748117  0.00251883]\n",
      " [ 0.00194791  0.99805212]\n",
      " [ 0.00347149  0.99652857]\n",
      " [ 0.00190049  0.99809951]\n",
      " [ 0.92691422  0.0730858 ]\n",
      " [ 0.00576194  0.99423802]\n",
      " [ 0.99999309  0.00000692]\n",
      " [ 0.99328679  0.00671315]] (0.585 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.00932042  0.99067956]\n",
      " [ 0.98126811  0.01873192]\n",
      " [ 0.00000272  0.99999726]\n",
      " [ 0.99942589  0.00057414]\n",
      " [ 0.99910527  0.00089473]\n",
      " [ 0.99921525  0.0007847 ]\n",
      " [ 0.99778569  0.00221424]\n",
      " [ 0.02739642  0.97260362]\n",
      " [ 0.01021037  0.98978966]\n",
      " [ 0.00009384  0.99990618]] (0.552 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into /tmp/pets_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0142552.\n",
      "dense shape (?, 32)\n",
      "logits shape (?, 2)\n",
      "labels shape (?,)\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-28-18:53:19\n",
      "INFO:tensorflow:Restoring parameters from /tmp/pets_convnet_model\\model.ckpt-1200\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-28-18:53:20\n",
      "INFO:tensorflow:Saving dict for global step 1200: accuracy = 0.5, global_step = 1200, loss = 1.55417\n",
      "{'global_step': 1200, 'loss': 1.5541741, 'accuracy': 0.5}\n"
     ]
    }
   ],
   "source": [
    "#X_train = np.array((X_train/255.0),dtype=np.float16)\n",
    "#X_test = np.array((X_test/255.0), dtype=np.float16)\n",
    "X_train = np.array((X_train/255.0),dtype=np.float32)\n",
    "X_test = np.array((X_test/255.0), dtype=np.float32)\n",
    "\n",
    "pets_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"/tmp/pets_convnet_model\")\n",
    "#pets_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn)\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": X_train}, y=y_train, batch_size=10,\n",
    "                                                      num_epochs=None, shuffle=True)\n",
    "pets_classifier.train(input_fn=train_input_fn, steps=num_steps, hooks=[logging_hook])\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": X_test}, y=y_test, num_epochs=1,shuffle=False)\n",
    "eval_results = pets_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'cats'), (1, 'dogs')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = list(enumerate(labels))\n",
    "print(e)\n",
    "y_test[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 predictions:  [0 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 0 0 1 1]\n",
      "First 3 animals:  [[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict_classes(X_test, verbose=0)\n",
    "print('First 3 predictions: ', y_test_pred[:])\n",
    "print('First 3 animals: ', y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "foto = 18\n",
    "fig1 = plt.figure() \n",
    "ax1 = fig1.add_subplot(2,2,1) \n",
    "ax1.imshow(X_test[foto])\n",
    "plt.title(y_test[foto])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test[10:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-652ccd959cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_resize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: data type not understood"
     ]
    }
   ],
   "source": [
    "np.array(im_resize).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 28, 28, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filipetheodoro/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend\n",
    "\n",
    "backend.clear_session()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
